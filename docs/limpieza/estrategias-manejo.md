# Estrategias de Manejo de Valores Faltantes

## Introducci√≥n

Una vez identificados los valores faltantes, el siguiente paso crucial es decidir c√≥mo manejarlos. No existe una soluci√≥n √∫nica; la estrategia √≥ptima depende del contexto del negocio, el tipo de datos, el porcentaje de valores faltantes, y el tipo de an√°lisis que se realizar√°. Esta secci√≥n cubre las principales estrategias y cu√°ndo aplicar cada una.

## üéØ Objetivos de esta Secci√≥n

- Comprender las diferentes estrategias para manejar valores faltantes
- Aplicar criterios para seleccionar la estrategia m√°s apropiada
- Implementar t√©cnicas de eliminaci√≥n y preservaci√≥n de datos
- Evaluar el impacto de cada estrategia en el an√°lisis
- Desarrollar un marco de decisi√≥n para casos complejos

## Estrategias Principales

### 1. Eliminaci√≥n (Deletion)
### 2. Imputaci√≥n (Imputation)
### 3. Marcado como Categor√≠a Especial
### 4. Modelado Expl√≠cito

## Dataset de Trabajo

```python
import pandas as pd
import numpy as np
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer, KNNImputer

# Dataset de empleados con diferentes tipos de valores faltantes
np.random.seed(42)

empleados = pd.DataFrame({
    'empleado_id': [f'E{i:03d}' for i in range(1, 201)],
    'nombre': [f'Empleado {i}' for i in range(1, 201)],
    'departamento': np.random.choice(['IT', 'Ventas', 'Marketing', 'RRHH', 'Finanzas'], 200),
    'salario': np.random.normal(50000, 15000, 200),
    'antiguedad': np.random.randint(1, 15, 200),
    'evaluacion': np.random.normal(7.5, 1.5, 200),
    'bonificacion': np.random.normal(5000, 2000, 200),
    'ciudad': np.random.choice(['Madrid', 'Barcelona', 'Valencia', 'Sevilla'], 200),
    'nivel_educacion': np.random.choice(['Bachillerato', 'Grado', 'M√°ster', 'Doctorado'], 200),
    'fecha_ingreso': pd.date_range('2010-01-01', '2023-12-31', periods=200)
})

# Introducir valores faltantes de manera realista
# 1. Salarios faltantes para empleados nuevos (pol√≠tica de confidencialidad)
empleados.loc[empleados['antiguedad'] < 2, 'salario'] = np.where(
    np.random.random(sum(empleados['antiguedad'] < 2)) < 0.3, np.nan, 
    empleados.loc[empleados['antiguedad'] < 2, 'salario']
)

# 2. Evaluaciones faltantes para algunos empleados
missing_eval_mask = np.random.random(200) < 0.15
empleados.loc[missing_eval_mask, 'evaluacion'] = np.nan

# 3. Bonificaciones faltantes (no todos los departamentos las tienen)
dept_no_bonus = ['RRHH']
empleados.loc[empleados['departamento'].isin(dept_no_bonus), 'bonificacion'] = np.nan

# 4. Algunas bonificaciones faltantes aleatoriamente
random_bonus_missing = np.random.random(200) < 0.1
empleados.loc[random_bonus_missing, 'bonificacion'] = np.nan

# 5. Nivel educaci√≥n faltante para empleados antiguos (datos no registrados)
empleados.loc[empleados['antiguedad'] > 10, 'nivel_educacion'] = np.where(
    np.random.random(sum(empleados['antiguedad'] > 10)) < 0.25, np.nan,
    empleados.loc[empleados['antiguedad'] > 10, 'nivel_educacion']
)

print("Dataset con valores faltantes introducidos:")
print(empleados.isna().sum())
print(f"\nForma del dataset: {empleados.shape}")
```

## Estrategia 1: Eliminaci√≥n de Datos

### Eliminaci√≥n de Filas (Listwise Deletion)

```python
# An√°lisis del impacto de eliminar filas completas
def analizar_impacto_eliminacion_filas(df):
    """Analiza el impacto de eliminar filas con valores faltantes."""
    original_count = len(df)
    
    # Eliminar filas con ANY valor faltante
    df_any_na = df.dropna()
    perdida_any = ((original_count - len(df_any_na)) / original_count) * 100
    
    # Eliminar filas con valores faltantes en columnas cr√≠ticas
    columnas_criticas = ['salario', 'evaluacion']  # Columnas esenciales para an√°lisis
    df_criticas = df.dropna(subset=columnas_criticas)
    perdida_criticas = ((original_count - len(df_criticas)) / original_count) * 100
    
    # An√°lisis de sesgo potencial
    def analizar_sesgo(df_original, df_filtrado, columna):
        if columna in df_original.columns and df_original[columna].dtype in ['int64', 'float64']:
            media_original = df_original[columna].mean()
            media_filtrada = df_filtrado[columna].mean()
            diferencia = abs(media_filtrada - media_original) / media_original * 100
            return diferencia
        return None
    
    sesgo_antiguedad = analizar_sesgo(df, df_any_na, 'antiguedad')
    
    resultado = {
        'Eliminaci√≥n ANY NA': {
            'Registros_Perdidos': original_count - len(df_any_na),
            'Porcentaje_Perdido': perdida_any,
            'Registros_Restantes': len(df_any_na)
        },
        'Eliminaci√≥n Columnas Cr√≠ticas': {
            'Registros_Perdidos': original_count - len(df_criticas),
            'Porcentaje_Perdido': perdida_criticas,
            'Registros_Restantes': len(df_criticas)
        },
        'An√°lisis_Sesgo': {
            'Cambio_Media_Antig√ºedad': f"{sesgo_antiguedad:.2f}%" if sesgo_antiguedad else "N/A"
        }
    }
    
    return resultado, df_any_na, df_criticas

impacto_eliminacion, df_sin_na, df_criticas_sin_na = analizar_impacto_eliminacion_filas(empleados)

print("IMPACTO DE ELIMINACI√ìN DE FILAS")
print("="*40)
for estrategia, datos in impacto_eliminacion.items():
    print(f"\n{estrategia}:")
    for metrica, valor in datos.items():
        print(f"  {metrica}: {valor}")
```

### Eliminaci√≥n de Columnas

```python
def evaluar_eliminacion_columnas(df, umbral_faltantes=0.5):
    """Eval√∫a qu√© columnas deber√≠an eliminarse por exceso de valores faltantes."""
    porcentaje_faltantes = df.isna().sum() / len(df)
    
    columnas_eliminar = porcentaje_faltantes[porcentaje_faltantes > umbral_faltantes].index.tolist()
    columnas_conservar = porcentaje_faltantes[porcentaje_faltantes <= umbral_faltantes].index.tolist()
    
    print(f"EVALUACI√ìN DE ELIMINACI√ìN DE COLUMNAS (umbral: {umbral_faltantes*100}%)")
    print("="*60)
    print(f"Columnas a eliminar: {columnas_eliminar}")
    print(f"Columnas a conservar: {columnas_conservar}")
    
    if columnas_eliminar:
        df_sin_columnas = df[columnas_conservar]
        registros_completos_nuevo = df_sin_columnas.dropna().shape[0]
        mejora = registros_completos_nuevo - df.dropna().shape[0]
        
        print(f"\nImpacto de eliminar columnas problem√°ticas:")
        print(f"  Registros completos originales: {df.dropna().shape[0]}")
        print(f"  Registros completos despu√©s: {registros_completos_nuevo}")
        print(f"  Mejora: +{mejora} registros ({mejora/len(df)*100:.1f}%)")
        
        return df_sin_columnas
    else:
        print("No hay columnas que excedan el umbral de eliminaci√≥n.")
        return df

# Evaluar diferentes umbrales
for umbral in [0.3, 0.5, 0.7]:
    print(f"\n{'='*20} UMBRAL {umbral*100}% {'='*20}")
    df_evaluado = evaluar_eliminacion_columnas(empleados, umbral)
```

## Estrategia 2: Imputaci√≥n de Valores

### Imputaci√≥n Simple

```python
def imputacion_simple(df):
    """Aplica diferentes m√©todos de imputaci√≥n simple."""
    df_imputado = df.copy()
    
    # 1. Media para variables num√©ricas
    columnas_numericas = df_imputado.select_dtypes(include=[np.number]).columns
    for col in columnas_numericas:
        if df_imputado[col].isna().any():
            media = df_imputado[col].mean()
            df_imputado[col].fillna(media, inplace=True)
            print(f"Imputaci√≥n por media - {col}: {media:.2f}")
    
    # 2. Moda para variables categ√≥ricas
    columnas_categoricas = df_imputado.select_dtypes(include=['object']).columns
    for col in columnas_categoricas:
        if df_imputado[col].isna().any():
            moda = df_imputado[col].mode()[0] if not df_imputado[col].mode().empty else 'Desconocido'
            df_imputado[col].fillna(moda, inplace=True)
            print(f"Imputaci√≥n por moda - {col}: {moda}")
    
    return df_imputado

print("IMPUTACI√ìN SIMPLE")
print("="*20)
empleados_imputacion_simple = imputacion_simple(empleados)
print(f"\nValores faltantes despu√©s de imputaci√≥n simple:")
print(empleados_imputacion_simple.isna().sum())
```

### Imputaci√≥n por Grupos

```python
def imputacion_por_grupos(df):
    """Realiza imputaci√≥n considerando grupos l√≥gicos."""
    df_imputado = df.copy()
    
    # Imputar salario por departamento y antiguedad
    def imputar_salario_inteligente(grupo):
        if 'salario' in grupo.columns and grupo['salario'].isna().any():
            # Usar mediana del grupo, si no hay datos, usar mediana general
            mediana_grupo = grupo['salario'].median()
            if pd.isna(mediana_grupo):
                mediana_grupo = df['salario'].median()
            grupo['salario'].fillna(mediana_grupo, inplace=True)
        return grupo
    
    # Agrupar por departamento y nivel de antiguedad
    df_imputado['grupo_antiguedad'] = pd.cut(df_imputado['antiguedad'], 
                                           bins=[0, 3, 7, 15], 
                                           labels=['Junior', 'Senior', 'Veterano'])
    
    df_imputado = df_imputado.groupby(['departamento', 'grupo_antiguedad']).apply(imputar_salario_inteligente)
    
    # Imputar evaluaci√≥n por departamento
    for dept in df_imputado['departamento'].unique():
        mask = df_imputado['departamento'] == dept
        if df_imputado.loc[mask, 'evaluacion'].isna().any():
            mediana_eval = df_imputado.loc[mask, 'evaluacion'].median()
            if pd.isna(mediana_eval):
                mediana_eval = df_imputado['evaluacion'].median()
            df_imputado.loc[mask, 'evaluacion'] = df_imputado.loc[mask, 'evaluacion'].fillna(mediana_eval)
            print(f"Imputaci√≥n evaluaci√≥n {dept}: {mediana_eval:.2f}")
    
    # Limpiar columna temporal
    df_imputado.drop('grupo_antiguedad', axis=1, inplace=True)
    
    return df_imputado

print("\nIMPUTACI√ìN POR GRUPOS")
print("="*25)
empleados_imputacion_grupos = imputacion_por_grupos(empleados)
print(f"\nValores faltantes despu√©s de imputaci√≥n por grupos:")
print(empleados_imputacion_grupos.isna().sum())
```

### Imputaci√≥n Avanzada

```python
def imputacion_avanzada(df):
    """Aplica t√©cnicas avanzadas de imputaci√≥n."""
    df_numerico = df.select_dtypes(include=[np.number])
    df_categorico = df.select_dtypes(include=['object'])
    
    # 1. Imputaci√≥n iterativa para variables num√©ricas
    print("Aplicando imputaci√≥n iterativa...")
    iterative_imputer = IterativeImputer(random_state=42, max_iter=10)
    df_numerico_imputado = pd.DataFrame(
        iterative_imputer.fit_transform(df_numerico),
        columns=df_numerico.columns,
        index=df_numerico.index
    )
    
    # 2. Imputaci√≥n KNN para una comparaci√≥n
    print("Aplicando imputaci√≥n KNN...")
    knn_imputer = KNNImputer(n_neighbors=5)
    df_numerico_knn = pd.DataFrame(
        knn_imputer.fit_transform(df_numerico),
        columns=df_numerico.columns,
        index=df_numerico.index
    )
    
    # 3. Para categ√≥ricas, usar la estrategia de grupos anterior
    df_categorico_imputado = df_categorico.copy()
    for col in df_categorico_imputado.columns:
        if df_categorico_imputado[col].isna().any():
            moda = df_categorico_imputado[col].mode()[0] if not df_categorico_imputado[col].mode().empty else 'Desconocido'
            df_categorico_imputado[col].fillna(moda, inplace=True)
    
    # Combinar resultados
    df_final_iterativo = pd.concat([df_categorico_imputado, df_numerico_imputado], axis=1)
    df_final_knn = pd.concat([df_categorico_imputado, df_numerico_knn], axis=1)
    
    return df_final_iterativo, df_final_knn

print("\nIMPUTACI√ìN AVANZADA")
print("="*20)
empleados_iterativo, empleados_knn = imputacion_avanzada(empleados)

print("Valores faltantes despu√©s de imputaci√≥n iterativa:")
print(empleados_iterativo.isna().sum())
print("\nValores faltantes despu√©s de imputaci√≥n KNN:")
print(empleados_knn.isna().sum())
```

## Estrategia 3: Marcado como Categor√≠a Especial

```python
def marcar_como_categoria_especial(df):
    """Trata valores faltantes como una categor√≠a especial."""
    df_marcado = df.copy()
    
    # Para variables categ√≥ricas, crear categor√≠a "No Disponible"
    columnas_categoricas = df_marcado.select_dtypes(include=['object']).columns
    for col in columnas_categoricas:
        if df_marcado[col].isna().any():
            df_marcado[col].fillna('No_Disponible', inplace=True)
            print(f"Marcado como 'No_Disponible' - {col}: {(df[col].isna().sum())} valores")
    
    # Para variables num√©ricas, crear flag indicador y usar valor centinela
    columnas_numericas = df_marcado.select_dtypes(include=[np.number]).columns
    for col in columnas_numericas:
        if df_marcado[col].isna().any():
            # Crear columna indicadora
            df_marcado[f'{col}_faltante'] = df_marcado[col].isna().astype(int)
            
            # Usar valor centinela (ej: -999 o valor fuera del rango normal)
            valor_centinela = -999
            df_marcado[col].fillna(valor_centinela, inplace=True)
            print(f"Marcado con centinela {valor_centinela} - {col}: {(df[col].isna().sum())} valores")
    
    return df_marcado

print("\nMARCADO COMO CATEGOR√çA ESPECIAL")
print("="*35)
empleados_marcado = marcar_como_categoria_especial(empleados)
print(f"\nNuevas columnas indicadoras creadas:")
nuevas_columnas = [col for col in empleados_marcado.columns if col.endswith('_faltante')]
print(nuevas_columnas)
```

## Evaluaci√≥n de Estrategias

```python
def evaluar_estrategias_imputacion(df_original, estrategias_dict):
    """Eval√∫a diferentes estrategias de imputaci√≥n."""
    evaluacion = {}
    
    # M√©tricas base del dataset original
    registros_originales = len(df_original)
    
    for nombre_estrategia, df_estrategia in estrategias_dict.items():
        evaluacion[nombre_estrategia] = {}
        
        # 1. Completitud
        evaluacion[nombre_estrategia]['Registros_Completos'] = len(df_estrategia.dropna())
        evaluacion[nombre_estrategia]['Porcentaje_Completitud'] = (
            len(df_estrategia.dropna()) / len(df_estrategia) * 100
        )
        
        # 2. Preservaci√≥n de datos
        evaluacion[nombre_estrategia]['Registros_Preservados'] = len(df_estrategia)
        evaluacion[nombre_estrategia]['Porcentaje_Preservado'] = (
            len(df_estrategia) / registros_originales * 100
        )
        
        # 3. Distribuci√≥n de variables clave (ejemplo: salario)
        if 'salario' in df_estrategia.columns:
            media_original = df_original['salario'].mean()
            std_original = df_original['salario'].std()
            media_estrategia = df_estrategia['salario'].mean()
            std_estrategia = df_estrategia['salario'].std()
            
            evaluacion[nombre_estrategia]['Cambio_Media_Salario'] = (
                abs(media_estrategia - media_original) / media_original * 100
            )
            evaluacion[nombre_estrategia]['Cambio_Std_Salario'] = (
                abs(std_estrategia - std_original) / std_original * 100
            )
    
    return evaluacion

# Preparar diccionario de estrategias para evaluaci√≥n
estrategias = {
    'Eliminaci√≥n_Completa': empleados.dropna(),
    'Eliminaci√≥n_Cr√≠ticas': empleados.dropna(subset=['salario', 'evaluacion']),
    'Imputaci√≥n_Simple': empleados_imputacion_simple,
    'Imputaci√≥n_Grupos': empleados_imputacion_grupos,
    'Imputaci√≥n_Iterativa': empleados_iterativo,
    'Imputaci√≥n_KNN': empleados_knn,
    'Marcado_Especial': empleados_marcado
}

evaluacion_resultados = evaluar_estrategias_imputacion(empleados, estrategias)

print("\nEVALUACI√ìN DE ESTRATEGIAS")
print("="*30)
df_evaluacion = pd.DataFrame(evaluacion_resultados).T
print(df_evaluacion.round(2))
```

## Marco de Decisi√≥n

```python
def recomendar_estrategia(df, contexto_negocio=None):
    """Recomienda estrategia basada en caracter√≠sticas de los datos y contexto."""
    
    # An√°lisis de caracter√≠sticas de los datos
    total_registros = len(df)
    porcentaje_completos = len(df.dropna()) / total_registros * 100
    columnas_con_faltantes = df.isna().any().sum()
    max_faltantes_columna = (df.isna().sum() / total_registros * 100).max()
    
    recomendaciones = []
    
    # Reglas de decisi√≥n
    if porcentaje_completos > 90:
        recomendaciones.append({
            'Estrategia': 'Eliminaci√≥n de Filas',
            'Raz√≥n': 'Alto porcentaje de registros completos (>90%)',
            'Prioridad': 'Alta'
        })
    
    if max_faltantes_columna > 50:
        recomendaciones.append({
            'Estrategia': 'Eliminaci√≥n de Columnas',
            'Raz√≥n': f'Columna con >50% faltantes ({max_faltantes_columna:.1f}%)',
            'Prioridad': 'Alta'
        })
    
    if 20 <= porcentaje_completos <= 80:
        recomendaciones.append({
            'Estrategia': 'Imputaci√≥n por Grupos',
            'Raz√≥n': 'Nivel moderado de faltantes, posible estructura en datos',
            'Prioridad': 'Media'
        })
    
    if total_registros > 1000 and porcentaje_completos < 70:
        recomendaciones.append({
            'Estrategia': 'Imputaci√≥n Avanzada (KNN/Iterativa)',
            'Raz√≥n': 'Dataset grande con muchos faltantes',
            'Prioridad': 'Media'
        })
    
    if contexto_negocio and 'regulatorio' in contexto_negocio.lower():
        recomendaciones.append({
            'Estrategia': 'Marcado como Categor√≠a Especial',
            'Raz√≥n': 'Contexto regulatorio requiere trazabilidad',
            'Prioridad': 'Alta'
        })
    
    # Si no hay recomendaciones espec√≠ficas
    if not recomendaciones:
        recomendaciones.append({
            'Estrategia': 'Imputaci√≥n Simple',
            'Raz√≥n': 'Estrategia segura por defecto',
            'Prioridad': 'Baja'
        })
    
    return recomendaciones

print("\nRECOMENDACIONES DE ESTRATEGIA")
print("="*35)
recomendaciones = recomendar_estrategia(empleados, "An√°lisis de RRHH para reporte regulatorio")

for i, rec in enumerate(recomendaciones, 1):
    print(f"{i}. {rec['Estrategia']} (Prioridad: {rec['Prioridad']})")
    print(f"   Raz√≥n: {rec['Raz√≥n']}")
```

## Casos Pr√°cticos

### Caso 1: Dataset de Ventas con Faltantes Estacionales

```python
def caso_ventas_estacionales():
    """Manejo de faltantes en datos de ventas con patrones estacionales."""
    # Simular datos de ventas con faltantes estacionales
    fechas = pd.date_range('2020-01-01', '2023-12-31', freq='D')
    ventas_data = {
        'fecha': fechas,
        'ventas': np.random.normal(1000, 200, len(fechas)),
        'region': np.random.choice(['Norte', 'Sur', 'Este', 'Oeste'], len(fechas)),
        'producto': np.random.choice(['A', 'B', 'C'], len(fechas))
    }
    
    df_ventas = pd.DataFrame(ventas_data)
    
    # Introducir faltantes estacionales (ej: menos datos en diciembre)
    mask_diciembre = df_ventas['fecha'].dt.month == 12
    faltantes_diciembre = np.random.random(mask_diciembre.sum()) < 0.3
    df_ventas.loc[mask_diciembre, 'ventas'] = np.where(faltantes_diciembre, np.nan, 
                                                      df_ventas.loc[mask_diciembre, 'ventas'])
    
    print("CASO: Ventas con Faltantes Estacionales")
    print("="*40)
    print(f"Total registros: {len(df_ventas)}")
    print(f"Faltantes por mes:")
    faltantes_por_mes = df_ventas.groupby(df_ventas['fecha'].dt.month)['ventas'].apply(lambda x: x.isna().sum())
    print(faltantes_por_mes)
    
    # Estrategia recomendada: Imputaci√≥n con suavizado estacional
    df_ventas['mes'] = df_ventas['fecha'].dt.month
    df_ventas['a√±o'] = df_ventas['fecha'].dt.year
    
    # Imputar usando promedio del mismo mes en otros a√±os
    for region in df_ventas['region'].unique():
        for producto in df_ventas['producto'].unique():
            for mes in df_ventas['mes'].unique():
                mask = (df_ventas['region'] == region) & \
                       (df_ventas['producto'] == producto) & \
                       (df_ventas['mes'] == mes)
                
                if df_ventas.loc[mask, 'ventas'].isna().any():
                    promedio_historico = df_ventas.loc[mask, 'ventas'].mean()
                    if not pd.isna(promedio_historico):
                        df_ventas.loc[mask, 'ventas'].fillna(promedio_historico, inplace=True)
    
    print(f"\nDespu√©s de imputaci√≥n estacional:")
    print(f"Valores faltantes restantes: {df_ventas['ventas'].isna().sum()}")
    
    return df_ventas

df_ventas_caso = caso_ventas_estacionales()
```

## Ejercicios Pr√°cticos

### Ejercicio 1: An√°lisis de Impacto
```python
# TODO: Para el dataset de empleados:
# 1. Compara el impacto de eliminar filas vs imputar por media en el an√°lisis de correlaci√≥n
# 2. ¬øCambia significativamente la correlaci√≥n entre salario y evaluaci√≥n?
# 3. ¬øQu√© estrategia preserva mejor las relaciones originales?

# Tu soluci√≥n aqu√≠:
```

### Ejercicio 2: Estrategia H√≠brida
```python
# TODO: Desarrolla una estrategia h√≠brida que:
# 1. Elimine columnas con >40% de faltantes
# 2. Use imputaci√≥n por grupos para variables num√©ricas
# 3. Marque como categor√≠a especial las variables categ√≥ricas
# 4. Eval√∫e el resultado final

# Tu soluci√≥n aqu√≠:
```

### Ejercicio 3: Validaci√≥n de Estrategia
```python
# TODO: Implementa una funci√≥n que:
# 1. Divida el dataset en train/test
# 2. Aplique diferentes estrategias al conjunto train
# 3. Eval√∫e qu√© tan bien predice el conjunto test
# 4. Recomiende la mejor estrategia basada en performance

# Tu soluci√≥n aqu√≠:
```

## Mejores Pr√°cticas

!!! tip "Gu√≠a para Selecci√≥n de Estrategias"
    1. **Analiza el mecanismo**: ¬øPor qu√© faltan los datos? (MCAR, MAR, MNAR)
    2. **Considera el contexto**: Requisitos del negocio y regulatorios
    3. **Eval√∫a el impacto**: Mide c√≥mo cada estrategia afecta el an√°lisis
    4. **Documenta decisiones**: Mant√©n registro de por qu√© elegiste cada estrategia
    5. **Valida resultados**: Verifica que la estrategia no introduce sesgos

### Plantilla de Decisi√≥n

```python
def plantilla_decision_faltantes(df, columna_objetivo=None):
    """Plantilla estructurada para decidir estrategia de manejo."""
    
    print("PLANTILLA DE DECISI√ìN PARA VALORES FALTANTES")
    print("="*50)
    
    # 1. Caracterizaci√≥n del problema
    total_registros = len(df)
    faltantes_por_columna = df.isna().sum()
    porcentaje_faltantes = (faltantes_por_columna / total_registros * 100).round(2)
    
    print("1. CARACTERIZACI√ìN DEL PROBLEMA:")
    print(f"   - Registros totales: {total_registros}")
    print(f"   - Columnas con faltantes: {(faltantes_por_columna > 0).sum()}")
    print(f"   - M√°ximo % faltantes: {porcentaje_faltantes.max()}%")
    
    # 2. An√°lisis de criticidad
    columnas_criticas = porcentaje_faltantes[porcentaje_faltantes > 30].index.tolist()
    columnas_moderadas = porcentaje_faltantes[(porcentaje_faltantes > 10) & (porcentaje_faltantes <= 30)].index.tolist()
    
    print("\n2. AN√ÅLISIS DE CRITICIDAD:")
    print(f"   - Columnas cr√≠ticas (>30%): {columnas_criticas}")
    print(f"   - Columnas moderadas (10-30%): {columnas_moderadas}")
    
    # 3. Recomendaciones
    print("\n3. RECOMENDACIONES:")
    if columnas_criticas:
        print("   - Considerar eliminaci√≥n de columnas cr√≠ticas")
    if len(df.dropna()) / total_registros > 0.8:
        print("   - Eliminaci√≥n de filas es viable (>80% completos)")
    else:
        print("   - Imputaci√≥n recomendada para preservar datos")
    
    # 4. Estrategia sugerida
    if columna_objetivo:
        faltantes_objetivo = df[columna_objetivo].isna().sum()
        print(f"\n4. AN√ÅLISIS VARIABLE OBJETIVO ({columna_objetivo}):")
        print(f"   - Faltantes en objetivo: {faltantes_objetivo} ({faltantes_objetivo/total_registros*100:.1f}%)")
        
        if faltantes_objetivo > total_registros * 0.1:
            print("   - ADVERTENCIA: Variable objetivo con muchos faltantes")

# Aplicar plantilla
plantilla_decision_faltantes(empleados, 'salario')
```

## Resumen

Las estrategias de manejo de valores faltantes te permiten:

- ‚úÖ Preservar la m√°xima cantidad de informaci√≥n √∫til
- ‚úÖ Mantener la validez estad√≠stica de los an√°lisis
- ‚úÖ Adaptar el enfoque al contexto espec√≠fico del negocio
- ‚úÖ Minimizar sesgos introducidos por el manejo de faltantes
- ‚úÖ Documentar y justificar decisiones metodol√≥gicas

**Pr√≥ximo paso**: Contin√∫a con [T√©cnicas de Imputaci√≥n](tecnicas-imputacion.md) para profundizar en m√©todos espec√≠ficos de imputaci√≥n de valores.